{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chapter 3: State Estimation\n",
        "\n",
        "## Principles of Indoor Positioning and Indoor Navigation\n",
        "\n",
        "---\n",
        "\n",
        "### üìö Learning Objectives\n",
        "\n",
        "By the end of this notebook, you will be able to:\n",
        "\n",
        "1. **Understand** the fundamental concepts of state estimation for positioning\n",
        "2. **Implement** Least Squares methods (LS, WLS, Iterative LS, Robust LS)\n",
        "3. **Apply** Kalman Filter (KF) for linear dynamic systems\n",
        "4. **Use** Extended Kalman Filter (EKF) for nonlinear systems\n",
        "5. **Compare** different estimators (EKF, UKF, Particle Filter)\n",
        "\n",
        "### üìñ Book Reference\n",
        "\n",
        "This notebook covers **Chapter 3: State Estimation** with implementations of:\n",
        "- **Eq. (3.1)-(3.4)**: Least Squares Methods\n",
        "- **Eq. (3.11)-(3.19)**: Kalman Filter\n",
        "- **Eq. (3.21)-(3.22)**: Extended Kalman Filter\n",
        "- **Eq. (3.24)-(3.30)**: Unscented Kalman Filter\n",
        "- **Eq. (3.32)-(3.34)**: Particle Filter\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Setup (Google Colab)\n",
        "\n",
        "Run this cell first to set up the environment. This will:\n",
        "1. Clone the IPIN Book Examples repository\n",
        "2. Install the package\n",
        "3. Import required modules\n",
        "\n",
        "**Note:** First run takes ~30-60 seconds. Subsequent runs are instant.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# IPIN Book Examples - Chapter 3: State Estimation\n",
        "# Run in Google Colab or Local Jupyter\n",
        "# ========================================\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Check if running in Colab\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    # Clone repository (only needed once per session)\n",
        "    if not os.path.exists('IPIN_Book_Examples'):\n",
        "        print(\"üì• Cloning IPIN Book Examples repository...\")\n",
        "        !git clone https://github.com/YOUR_USERNAME/IPIN_Book_Examples.git\n",
        "        %cd IPIN_Book_Examples\n",
        "        print(\"üì¶ Installing package...\")\n",
        "        !pip install -e . -q\n",
        "    else:\n",
        "        %cd IPIN_Book_Examples\n",
        "        print(\"‚úÖ Repository already cloned.\")\n",
        "else:\n",
        "    # Running locally - ensure we're in the right directory\n",
        "    if os.path.basename(os.getcwd()) == 'notebooks':\n",
        "        os.chdir('..')\n",
        "    print(f\"üìÇ Working directory: {os.getcwd()}\")\n",
        "\n",
        "# Import core libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Ellipse, Circle\n",
        "\n",
        "# Configure matplotlib for inline display\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = [12, 8]\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "# Import IPIN core modules\n",
        "from core.estimators import (\n",
        "    linear_least_squares,\n",
        "    weighted_least_squares,\n",
        "    iterative_least_squares,\n",
        "    robust_least_squares,\n",
        "    KalmanFilter,\n",
        "    ExtendedKalmanFilter,\n",
        "    UnscentedKalmanFilter,\n",
        "    ParticleFilter,\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ Setup complete! All core modules loaded.\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Part 1: Least Squares Methods\n",
        "\n",
        "## 1.1 Theory Overview\n",
        "\n",
        "Least Squares (LS) estimation minimizes the sum of squared residuals between measurements and predictions.\n",
        "\n",
        "### Linear Least Squares - Eq. (3.1)\n",
        "\n",
        "Given the linear measurement model:\n",
        "$$\\mathbf{z} = \\mathbf{H}\\mathbf{x} + \\mathbf{v}$$\n",
        "\n",
        "The LS estimate is:\n",
        "$$\\hat{\\mathbf{x}} = (\\mathbf{H}^T \\mathbf{H})^{-1} \\mathbf{H}^T \\mathbf{z}$$\n",
        "\n",
        "### Weighted Least Squares - Eq. (3.2)\n",
        "\n",
        "When measurements have different accuracies, we weight them:\n",
        "$$\\hat{\\mathbf{x}} = (\\mathbf{H}^T \\mathbf{W} \\mathbf{H})^{-1} \\mathbf{H}^T \\mathbf{W} \\mathbf{z}$$\n",
        "\n",
        "where $\\mathbf{W} = \\mathbf{R}^{-1}$ is the inverse of measurement covariance.\n",
        "\n",
        "### Iterative Least Squares (Gauss-Newton) - Eq. (3.3)\n",
        "\n",
        "For nonlinear problems, we linearize and iterate:\n",
        "$$\\mathbf{x}^{(k+1)} = \\mathbf{x}^{(k)} + (\\mathbf{H}^T \\mathbf{H})^{-1} \\mathbf{H}^T (\\mathbf{z} - h(\\mathbf{x}^{(k)}))$$\n",
        "\n",
        "### Robust Least Squares - Eq. (3.4)\n",
        "\n",
        "Uses robust loss functions (Huber, Cauchy, Tukey) to downweight outliers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.2 Positioning Scenario Setup\n",
        "\n",
        "We'll use a common indoor positioning scenario: **2D positioning from range measurements** (Time-of-Arrival).\n",
        "\n",
        "- 4 anchors at corners of a 10m √ó 10m room\n",
        "- Unknown target position to estimate\n",
        "- Range measurements from target to each anchor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define positioning scenario\n",
        "def setup_positioning_scenario():\n",
        "    \"\"\"Create a 2D positioning scenario with 4 anchors.\"\"\"\n",
        "    # Anchor positions at corners of 10m √ó 10m room\n",
        "    anchors = np.array([\n",
        "        [0.0, 0.0],   # Bottom-left\n",
        "        [10.0, 0.0],  # Bottom-right\n",
        "        [0.0, 10.0],  # Top-left\n",
        "        [10.0, 10.0]  # Top-right\n",
        "    ])\n",
        "    \n",
        "    # True target position (unknown to estimator)\n",
        "    true_position = np.array([3.0, 4.0])\n",
        "    \n",
        "    return anchors, true_position\n",
        "\n",
        "def compute_ranges(position, anchors, noise_std=0.0):\n",
        "    \"\"\"Compute ranges from position to anchors with optional noise.\"\"\"\n",
        "    true_ranges = np.linalg.norm(anchors - position, axis=1)\n",
        "    if noise_std > 0:\n",
        "        true_ranges += noise_std * np.random.randn(len(anchors))\n",
        "    return true_ranges\n",
        "\n",
        "# Set up scenario\n",
        "anchors, true_position = setup_positioning_scenario()\n",
        "\n",
        "print(\"üìç Positioning Scenario\")\n",
        "print(\"=\"*40)\n",
        "print(f\"Room size: 10m √ó 10m\")\n",
        "print(f\"Number of anchors: {len(anchors)}\")\n",
        "print(f\"\\nAnchor positions:\")\n",
        "for i, a in enumerate(anchors):\n",
        "    print(f\"  Anchor {i}: ({a[0]:.1f}, {a[1]:.1f}) m\")\n",
        "print(f\"\\nTrue target position: ({true_position[0]:.1f}, {true_position[1]:.1f}) m\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the scenario\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "\n",
        "# Draw room boundary\n",
        "ax.plot([0, 10, 10, 0, 0], [0, 0, 10, 10, 0], 'k-', linewidth=2, label='Room')\n",
        "\n",
        "# Plot anchors\n",
        "ax.scatter(anchors[:, 0], anchors[:, 1], s=300, c='blue', marker='^', \n",
        "           label='Anchors', zorder=5, edgecolors='black', linewidths=2)\n",
        "for i, a in enumerate(anchors):\n",
        "    ax.annotate(f'A{i}', (a[0]+0.3, a[1]+0.3), fontsize=12, fontweight='bold')\n",
        "\n",
        "# Plot true position\n",
        "ax.scatter(true_position[0], true_position[1], s=400, c='green', marker='*', \n",
        "           label='True Position', zorder=5, edgecolors='black', linewidths=2)\n",
        "\n",
        "# Draw range circles\n",
        "ranges = compute_ranges(true_position, anchors)\n",
        "for i, (anchor, r) in enumerate(zip(anchors, ranges)):\n",
        "    circle = Circle(anchor, r, fill=False, edgecolor='blue', alpha=0.3, linestyle='--')\n",
        "    ax.add_patch(circle)\n",
        "\n",
        "ax.set_xlabel('X (m)', fontsize=14)\n",
        "ax.set_ylabel('Y (m)', fontsize=14)\n",
        "ax.set_title('2D Positioning Scenario\\n(Range circles from each anchor)', fontsize=16, fontweight='bold')\n",
        "ax.legend(fontsize=12, loc='upper right')\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_xlim(-2, 12)\n",
        "ax.set_ylim(-2, 12)\n",
        "ax.set_aspect('equal')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüìè True ranges to each anchor:\")\n",
        "for i, r in enumerate(ranges):\n",
        "    print(f\"  Anchor {i}: {r:.3f} m\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.3 Example: Linear Least Squares\n",
        "\n",
        "The range measurement model is nonlinear:\n",
        "$$r_i = \\sqrt{(x - x_i)^2 + (y - y_i)^2}$$\n",
        "\n",
        "We linearize around an initial guess $\\mathbf{x}_0$:\n",
        "$$\\mathbf{H} = \\frac{\\partial \\mathbf{r}}{\\partial \\mathbf{x}} = \\begin{bmatrix} \\frac{x_0 - x_1}{r_1} & \\frac{y_0 - y_1}{r_1} \\\\ \\vdots & \\vdots \\end{bmatrix}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 1: Linear Least Squares\n",
        "print(\"=\"*70)\n",
        "print(\"EXAMPLE 1: Linear Least Squares (LS) - Eq. (3.1)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Generate noisy measurements\n",
        "np.random.seed(42)\n",
        "noise_std = 0.1  # 10 cm measurement noise\n",
        "ranges = compute_ranges(true_position, anchors, noise_std=noise_std)\n",
        "\n",
        "print(f\"\\nMeasurement noise: œÉ = {noise_std} m\")\n",
        "print(f\"\\nNoisy range measurements:\")\n",
        "for i, r in enumerate(ranges):\n",
        "    true_r = np.linalg.norm(true_position - anchors[i])\n",
        "    print(f\"  Anchor {i}: {r:.3f} m (true: {true_r:.3f} m, error: {r-true_r:+.3f} m)\")\n",
        "\n",
        "# Initial guess (center of room)\n",
        "x0 = np.array([5.0, 5.0])\n",
        "print(f\"\\nInitial guess: ({x0[0]}, {x0[1]}) m\")\n",
        "\n",
        "# Linearize: compute Jacobian at x0\n",
        "diff = x0 - anchors  # [4, 2]\n",
        "ranges_at_x0 = np.linalg.norm(diff, axis=1, keepdims=True)  # [4, 1]\n",
        "H = diff / ranges_at_x0  # Jacobian: ‚àÇr/‚àÇx\n",
        "\n",
        "# Observation vector: residual = measured - predicted\n",
        "b = ranges - np.linalg.norm(anchors - x0, axis=1)\n",
        "\n",
        "# Solve Linear LS: xÃÇ = x0 + (H'H)‚Åª¬πH'b\n",
        "dx, P = linear_least_squares(H, b)\n",
        "position_ls = x0 + dx\n",
        "\n",
        "# Calculate error\n",
        "error = np.linalg.norm(position_ls - true_position)\n",
        "\n",
        "print(f\"\\nüìä Results:\")\n",
        "print(f\"  True position:     ({true_position[0]:.3f}, {true_position[1]:.3f}) m\")\n",
        "print(f\"  LS estimate:       ({position_ls[0]:.3f}, {position_ls[1]:.3f}) m\")\n",
        "print(f\"  Position error:    {error:.4f} m\")\n",
        "print(f\"\\n  Covariance matrix:\")\n",
        "print(f\"  {P}\")\n",
        "print(f\"  Position std dev: ({np.sqrt(P[0,0]):.4f}, {np.sqrt(P[1,1]):.4f}) m\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.4 Example: Robust Least Squares (Outlier Rejection)\n",
        "\n",
        "In real environments, measurements can be corrupted by outliers (e.g., NLOS multipath). Robust estimators use loss functions that reduce the influence of outliers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Robust Least Squares\n",
        "print(\"=\"*70)\n",
        "print(\"EXAMPLE: Robust Least Squares (Outlier Rejection) - Eq. (3.4)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Generate measurements with an OUTLIER\n",
        "np.random.seed(42)\n",
        "ranges_clean = compute_ranges(true_position, anchors, noise_std=0.1)\n",
        "ranges_outlier = ranges_clean.copy()\n",
        "ranges_outlier[2] += 3.0  # Add 3m outlier to anchor 2 (NLOS!)\n",
        "\n",
        "print(f\"\\n‚ö†Ô∏è Added 3.0 m outlier to Anchor 2 (simulating NLOS)\")\n",
        "print(f\"\\nRange measurements:\")\n",
        "for i, (clean, outlier) in enumerate(zip(ranges_clean, ranges_outlier)):\n",
        "    status = \"‚ùå OUTLIER\" if i == 2 else \"‚úì\"\n",
        "    print(f\"  Anchor {i}: {outlier:.3f} m (clean: {clean:.3f} m) {status}\")\n",
        "\n",
        "# Linearization\n",
        "x0 = np.array([5.0, 5.0])\n",
        "diff = x0 - anchors\n",
        "ranges_at_x0 = np.linalg.norm(diff, axis=1, keepdims=True)\n",
        "H = diff / ranges_at_x0\n",
        "b = ranges_outlier - np.linalg.norm(anchors - x0, axis=1)\n",
        "\n",
        "# Standard LS (corrupted by outlier)\n",
        "dx_ls, _ = linear_least_squares(H, b)\n",
        "position_ls_outlier = x0 + dx_ls\n",
        "\n",
        "# Robust LS with different loss functions\n",
        "methods = ['huber', 'cauchy', 'tukey']\n",
        "results = {}\n",
        "\n",
        "for method in methods:\n",
        "    dx_robust, P_robust, weights = robust_least_squares(H, b, method=method, threshold=2.0)\n",
        "    position_robust = x0 + dx_robust\n",
        "    results[method] = {\n",
        "        'position': position_robust,\n",
        "        'error': np.linalg.norm(position_robust - true_position),\n",
        "        'outlier_weight': weights[2]\n",
        "    }\n",
        "\n",
        "error_ls = np.linalg.norm(position_ls_outlier - true_position)\n",
        "\n",
        "print(f\"\\nüìä Results:\")\n",
        "print(f\"  True position:      ({true_position[0]:.3f}, {true_position[1]:.3f}) m\")\n",
        "print(f\"  Standard LS:        ({position_ls_outlier[0]:.3f}, {position_ls_outlier[1]:.3f}) m  [error: {error_ls:.4f} m] ‚ùå Corrupted!\")\n",
        "print()\n",
        "for method, result in results.items():\n",
        "    pos = result['position']\n",
        "    print(f\"  {method.capitalize():8s} LS:      ({pos[0]:.3f}, {pos[1]:.3f}) m  [error: {result['error']:.4f} m]  outlier weight: {result['outlier_weight']:.3f}\")\n",
        "\n",
        "print(f\"\\nüí° Robust methods downweight the outlier (weight << 1.0) and recover the true position!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Part 2: Kalman Filter\n",
        "\n",
        "## 2.1 Theory Overview\n",
        "\n",
        "The Kalman Filter is the optimal estimator for **linear systems** with **Gaussian noise**.\n",
        "\n",
        "**State transition:** x_k = F * x_{k-1} + w_k\n",
        "\n",
        "**Measurement:** z_k = H * x_k + v_k\n",
        "\n",
        "**Prediction Step (Eq. 3.11-3.12):** Propagate state and covariance\n",
        "\n",
        "**Update Step (Eq. 3.17-3.19):** Correct with measurement using Kalman gain\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.2 Example: 1D Constant Velocity Tracking\n",
        "\n",
        "We'll track a target moving in 1D with constant velocity, using noisy position measurements.\n",
        "\n",
        "**State vector:** x = [position, velocity]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1D Kalman Filter Example\n",
        "print(\"=\"*70)\n",
        "print(\"EXAMPLE: 1D Constant Velocity Tracking with Kalman Filter\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Simulation parameters\n",
        "dt = 0.1  # Time step (seconds)\n",
        "t_max = 10.0  # Total time (seconds)\n",
        "n_steps = int(t_max / dt)\n",
        "\n",
        "# True initial state: [position, velocity]\n",
        "true_x0 = np.array([0.0, 2.0])  # Start at x=0, velocity=2 m/s\n",
        "\n",
        "# State transition matrix (constant velocity model) - Eq. (3.11)\n",
        "F = np.array([[1.0, dt], [0.0, 1.0]])\n",
        "\n",
        "# Process noise covariance - Eq. (3.12)\n",
        "q = 0.1  # Process noise intensity\n",
        "Q = q * np.array([[dt**3/3, dt**2/2], [dt**2/2, dt]])\n",
        "\n",
        "# Measurement matrix (observe position only) - Eq. (3.8)\n",
        "H = np.array([[1.0, 0.0]])\n",
        "\n",
        "# Measurement noise covariance\n",
        "measurement_std = 0.5  # meters\n",
        "R = np.array([[measurement_std**2]])\n",
        "\n",
        "# Initial estimate (poor velocity estimate)\n",
        "x0_est = np.array([0.0, 0.0])\n",
        "P0 = np.diag([1.0, 5.0])  # High uncertainty in velocity\n",
        "\n",
        "print(f\"\\nSimulation Parameters:\")\n",
        "print(f\"  Time step: {dt} s, Duration: {t_max} s\")\n",
        "print(f\"  True initial: pos={true_x0[0]} m, vel={true_x0[1]} m/s\")\n",
        "print(f\"  Measurement noise: {measurement_std} m\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Generate true trajectory and run Kalman Filter\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate true trajectory\n",
        "true_states = [true_x0.copy()]\n",
        "true_state = true_x0.copy()\n",
        "\n",
        "for _ in range(n_steps):\n",
        "    process_noise = np.random.multivariate_normal(np.zeros(2), Q)\n",
        "    true_state = F @ true_state + process_noise\n",
        "    true_states.append(true_state.copy())\n",
        "\n",
        "# Generate noisy measurements\n",
        "measurements = []\n",
        "for state in true_states[1:]:\n",
        "    true_measurement = H @ state\n",
        "    noise = np.random.normal(0, measurement_std)\n",
        "    measurements.append(true_measurement[0] + noise)\n",
        "\n",
        "# Run Kalman Filter\n",
        "print(\"\\nRunning Kalman Filter...\")\n",
        "kf = KalmanFilter(F, Q, H, R, x0_est, P0)\n",
        "\n",
        "estimates = [x0_est.copy()]\n",
        "covariances = [P0.copy()]\n",
        "\n",
        "for z in measurements:\n",
        "    kf.predict(dt=dt)\n",
        "    kf.update(np.array([z]))\n",
        "    x_est, P_est = kf.get_state()\n",
        "    estimates.append(x_est.copy())\n",
        "    covariances.append(P_est.copy())\n",
        "\n",
        "# Convert to arrays\n",
        "true_states = np.array(true_states)\n",
        "estimates = np.array(estimates)\n",
        "time = np.arange(n_steps + 1) * dt\n",
        "\n",
        "# Compute errors\n",
        "position_errors = np.abs(estimates[:, 0] - true_states[:, 0])\n",
        "velocity_errors = np.abs(estimates[:, 1] - true_states[:, 1])\n",
        "\n",
        "print(f\"\\nResults:\")\n",
        "print(f\"  Mean position error (after convergence): {np.mean(position_errors[20:]):.4f} m\")\n",
        "print(f\"  Mean velocity error (after convergence): {np.mean(velocity_errors[20:]):.4f} m/s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization: Kalman Filter Results\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Plot 1: Position vs Time\n",
        "ax = axes[0, 0]\n",
        "ax.plot(time, true_states[:, 0], 'g-', linewidth=2, label='True Position')\n",
        "ax.plot(time[1:], measurements, 'r.', alpha=0.5, markersize=4, label='Measurements')\n",
        "ax.plot(time, estimates[:, 0], 'b-', linewidth=2, label='KF Estimate')\n",
        "\n",
        "# Uncertainty bounds\n",
        "pos_std = np.array([np.sqrt(P[0, 0]) for P in covariances])\n",
        "ax.fill_between(time, estimates[:, 0] - 2*pos_std, estimates[:, 0] + 2*pos_std,\n",
        "                alpha=0.2, color='blue', label='2-sigma bounds')\n",
        "\n",
        "ax.set_xlabel('Time [s]')\n",
        "ax.set_ylabel('Position [m]')\n",
        "ax.set_title('Position Tracking', fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Velocity vs Time\n",
        "ax = axes[0, 1]\n",
        "ax.plot(time, true_states[:, 1], 'g-', linewidth=2, label='True Velocity')\n",
        "ax.plot(time, estimates[:, 1], 'b-', linewidth=2, label='KF Estimate')\n",
        "ax.set_xlabel('Time [s]')\n",
        "ax.set_ylabel('Velocity [m/s]')\n",
        "ax.set_title('Velocity Estimation (unobserved!)', fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 3: Position Error\n",
        "ax = axes[1, 0]\n",
        "ax.plot(time, position_errors, 'r-', linewidth=2)\n",
        "ax.axhline(y=measurement_std, color='k', linestyle='--', label=f'Meas. noise')\n",
        "ax.set_xlabel('Time [s]')\n",
        "ax.set_ylabel('Position Error [m]')\n",
        "ax.set_title('Position Error', fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 4: Velocity Error\n",
        "ax = axes[1, 1]\n",
        "ax.plot(time, velocity_errors, 'r-', linewidth=2)\n",
        "ax.set_xlabel('Time [s]')\n",
        "ax.set_ylabel('Velocity Error [m/s]')\n",
        "ax.set_title('Velocity Error', fontweight='bold')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nKey observations:\")\n",
        "print(\"  - KF provides smoother estimates than raw measurements\")\n",
        "print(\"  - Velocity is estimated even though only position is observed\")\n",
        "print(\"  - Error stays below measurement noise after convergence\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Summary\n",
        "\n",
        "In this notebook, we covered:\n",
        "\n",
        "1. **Least Squares Methods** (Eq. 3.1-3.4)\n",
        "   - Linear LS for overdetermined systems\n",
        "   - Weighted LS for heterogeneous measurements\n",
        "   - Robust LS for outlier rejection\n",
        "\n",
        "2. **Kalman Filter** (Eq. 3.11-3.19)\n",
        "   - Prediction and update steps\n",
        "   - Estimating unobserved states (velocity from position)\n",
        "   - Uncertainty quantification\n",
        "\n",
        "**Next Steps:** \n",
        "- Explore Extended Kalman Filter (EKF) for nonlinear systems\n",
        "- Try the full comparison example: `python -m ch3_estimators.example_comparison`\n",
        "- Apply to Chapter 4 (RF Positioning), Chapter 6 (Dead Reckoning), and Chapter 8 (Sensor Fusion)!\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
