{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chapter 5: Fingerprinting-based Indoor Positioning\n",
        "\n",
        "## Principles of Indoor Positioning and Indoor Navigation\n",
        "\n",
        "---\n",
        "\n",
        "### üìö Learning Objectives\n",
        "\n",
        "By the end of this notebook, you will be able to:\n",
        "\n",
        "1. **Understand** the fingerprinting paradigm (offline training + online positioning)\n",
        "2. **Implement** deterministic methods (Nearest Neighbor, k-Nearest Neighbor)\n",
        "3. **Apply** probabilistic methods (Bayesian inference, MAP, Posterior Mean)\n",
        "4. **Compare** different methods in terms of accuracy and speed\n",
        "5. **Analyze** the impact of database density and measurement noise\n",
        "\n",
        "### üìñ Book Reference\n",
        "\n",
        "This notebook covers **Chapter 5: Fingerprinting-based Indoor Positioning** with:\n",
        "- **Eq. (5.1)**: Nearest Neighbor (NN) positioning\n",
        "- **Eq. (5.2)**: k-Nearest Neighbor (k-NN) weighted positioning\n",
        "- **Eq. (5.3)-(5.5)**: Probabilistic/Bayesian methods (likelihood, MAP, posterior mean)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Setup (Google Colab)\n",
        "\n",
        "**Set the `GITHUB_REPO` variable below to your repository URL, then run the setup cell.**\n",
        "\n",
        "Example: `GITHUB_REPO = \"https://github.com/YOUR_USERNAME/IPIN-Examples.git\"`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# IPIN Book Examples - Chapter 5: Fingerprinting\n",
        "# ========================================\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# ============ CONFIGURATION ============\n",
        "GITHUB_REPO = None  # Set your repo URL, e.g., \"https://github.com/username/IPIN-Examples.git\"\n",
        "# =======================================\n",
        "\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    if os.path.exists('/content/IPIN-Examples/core'):\n",
        "        os.chdir('/content/IPIN-Examples')\n",
        "        print(\"‚úÖ Repository already available.\")\n",
        "    elif GITHUB_REPO:\n",
        "        print(f\"üì• Cloning from {GITHUB_REPO}...\")\n",
        "        get_ipython().system(f'git clone {GITHUB_REPO}')\n",
        "        os.chdir('/content/IPIN-Examples')\n",
        "        get_ipython().system('pip install -e . -q')\n",
        "        print(\"‚úÖ Setup from GitHub complete!\")\n",
        "    else:\n",
        "        print(\"‚ùå ERROR: GITHUB_REPO not set!\")\n",
        "        print(\"Please set GITHUB_REPO = 'https://github.com/YOUR_USERNAME/IPIN-Examples.git'\")\n",
        "        raise ValueError(\"GITHUB_REPO not configured.\")\n",
        "else:\n",
        "    if os.path.basename(os.getcwd()) == 'notebooks':\n",
        "        os.chdir('..')\n",
        "    print(f\"üìÇ Working directory: {os.getcwd()}\")\n",
        "\n",
        "# Import libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "get_ipython().run_line_magic('matplotlib', 'inline')\n",
        "plt.rcParams['figure.figsize'] = [12, 8]\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "\n",
        "# Import fingerprinting modules\n",
        "from core.fingerprinting import (\n",
        "    load_fingerprint_database,\n",
        "    nn_localize,\n",
        "    knn_localize,\n",
        "    fit_gaussian_naive_bayes,\n",
        "    map_localize,\n",
        "    posterior_mean_localize,\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ Setup complete! Fingerprinting modules loaded.\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Part 1: Fingerprinting Overview\n",
        "\n",
        "## 1.1 The Fingerprinting Paradigm\n",
        "\n",
        "Fingerprinting uses a **pattern-matching** approach instead of geometric models:\n",
        "\n",
        "### Offline Phase (Training)\n",
        "1. Survey the environment at known **Reference Points (RPs)**\n",
        "2. Record **RSS fingerprints** (signal strengths from multiple APs) at each RP\n",
        "3. Build a **fingerprint database**: `{(location‚ÇÅ, fingerprint‚ÇÅ), (location‚ÇÇ, fingerprint‚ÇÇ), ...}`\n",
        "\n",
        "### Online Phase (Positioning)\n",
        "1. Measure current RSS fingerprint at unknown location\n",
        "2. Compare against database using distance metrics\n",
        "3. Estimate position based on best-matching reference points\n",
        "\n",
        "## 1.2 Why Fingerprinting?\n",
        "\n",
        "| Advantage | Description |\n",
        "|-----------|-------------|\n",
        "| **No propagation model** | Doesn't need path-loss exponent calibration |\n",
        "| **Handles multipath** | Database captures actual signal behavior |\n",
        "| **Works with any RF** | WiFi, BLE, cellular, etc. |\n",
        "\n",
        "| Disadvantage | Description |\n",
        "|--------------|-------------|\n",
        "| **Site survey required** | Labor-intensive database collection |\n",
        "| **Environment changes** | Database can become outdated |\n",
        "| **Discrete locations** | Accuracy limited by RP density |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load fingerprint database\n",
        "print(\"=\"*70)\n",
        "print(\"Loading Fingerprint Database\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "db_path = Path(\"data/sim/ch5_wifi_fingerprint_grid\")\n",
        "db = load_fingerprint_database(db_path)\n",
        "\n",
        "print(f\"\\nüìÅ Database loaded from: {db_path}\")\n",
        "print(f\"\\nüìä Database Statistics:\")\n",
        "print(f\"  Reference Points: {len(db.locations)}\")\n",
        "print(f\"  Access Points:    {db.features.shape[1]}\")\n",
        "print(f\"  Floors:           {db.floor_list}\")\n",
        "print(f\"\\nüìç Spatial Coverage:\")\n",
        "print(f\"  X range: [{db.locations[:, 0].min():.1f}, {db.locations[:, 0].max():.1f}] m\")\n",
        "print(f\"  Y range: [{db.locations[:, 1].min():.1f}, {db.locations[:, 1].max():.1f}] m\")\n",
        "print(f\"\\nüì° RSS Statistics:\")\n",
        "print(f\"  Mean RSS:  {db.features.mean():.1f} dBm\")\n",
        "print(f\"  RSS range: [{db.features.min():.1f}, {db.features.max():.1f}] dBm\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize database\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Plot 1: Reference point locations\n",
        "ax1 = axes[0]\n",
        "floor_id = 0  # Show floor 0\n",
        "floor_mask = db.get_floor_mask(floor_id)\n",
        "ax1.scatter(db.locations[floor_mask, 0], db.locations[floor_mask, 1], \n",
        "            c='blue', marker='s', s=60, alpha=0.7, label='Reference Points')\n",
        "ax1.set_xlabel('X (m)', fontsize=12)\n",
        "ax1.set_ylabel('Y (m)', fontsize=12)\n",
        "ax1.set_title(f'Reference Point Layout (Floor {floor_id})', fontsize=14, fontweight='bold')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.set_aspect('equal')\n",
        "\n",
        "# Plot 2: RSS heatmap for first AP\n",
        "ax2 = axes[1]\n",
        "floor_locs = db.locations[floor_mask]\n",
        "floor_rss = db.features[floor_mask, 0]  # First AP\n",
        "scatter = ax2.scatter(floor_locs[:, 0], floor_locs[:, 1], \n",
        "                       c=floor_rss, cmap='RdYlGn', s=60, alpha=0.8)\n",
        "cbar = plt.colorbar(scatter, ax=ax2)\n",
        "cbar.set_label('RSS (dBm)', fontsize=11)\n",
        "ax2.set_xlabel('X (m)', fontsize=12)\n",
        "ax2.set_ylabel('Y (m)', fontsize=12)\n",
        "ax2.set_title('RSS Fingerprint (AP #1)', fontsize=14, fontweight='bold')\n",
        "ax2.set_aspect('equal')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüí° Observation: RSS varies spatially - this pattern enables positioning!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Part 2: Deterministic Methods\n",
        "\n",
        "## 2.1 Nearest Neighbor (NN) - Eq. 5.1\n",
        "\n",
        "Find the reference point with the most similar fingerprint:\n",
        "\n",
        "$$i^* = \\arg\\min_i D(\\mathbf{z}, \\mathbf{f}_i)$$\n",
        "\n",
        "$$\\hat{\\mathbf{x}} = \\mathbf{x}_{i^*}$$\n",
        "\n",
        "where:\n",
        "- $\\mathbf{z}$ = query fingerprint (measured RSS values)\n",
        "- $\\mathbf{f}_i$ = database fingerprint at reference point $i$\n",
        "- $D(\\cdot, \\cdot)$ = distance metric (Euclidean, Manhattan, etc.)\n",
        "\n",
        "## 2.2 k-Nearest Neighbor (k-NN) - Eq. 5.2\n",
        "\n",
        "Average the positions of the k closest reference points:\n",
        "\n",
        "$$\\hat{\\mathbf{x}} = \\frac{\\sum_{i \\in \\mathcal{N}_k} w_i \\mathbf{x}_i}{\\sum_{i \\in \\mathcal{N}_k} w_i}$$\n",
        "\n",
        "where:\n",
        "- $\\mathcal{N}_k$ = set of k nearest neighbors\n",
        "- $w_i$ = weight (uniform: $w_i=1$, or inverse distance: $w_i = 1/D_i$)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate test queries by interpolating from database\n",
        "def generate_test_queries(db, n_queries, floor_id, noise_std=0.0, seed=42):\n",
        "    \"\"\"Generate test fingerprints at random locations.\"\"\"\n",
        "    np.random.seed(seed)\n",
        "    \n",
        "    floor_mask = db.get_floor_mask(floor_id)\n",
        "    rp_locs = db.locations[floor_mask]\n",
        "    rp_features = db.features[floor_mask]\n",
        "    \n",
        "    # Random locations within bounding box\n",
        "    min_x, max_x = rp_locs[:, 0].min(), rp_locs[:, 0].max()\n",
        "    min_y, max_y = rp_locs[:, 1].min(), rp_locs[:, 1].max()\n",
        "    \n",
        "    true_locs = np.column_stack([\n",
        "        np.random.uniform(min_x + 2, max_x - 2, n_queries),\n",
        "        np.random.uniform(min_y + 2, max_y - 2, n_queries),\n",
        "    ])\n",
        "    \n",
        "    # Interpolate fingerprints from nearby RPs\n",
        "    queries = []\n",
        "    for loc in true_locs:\n",
        "        dists = np.linalg.norm(rp_locs - loc, axis=1)\n",
        "        k_nearest = min(4, len(dists))\n",
        "        nearest_idx = np.argpartition(dists, k_nearest)[:k_nearest]\n",
        "        \n",
        "        weights = 1.0 / (dists[nearest_idx] + 1e-3)\n",
        "        weights /= weights.sum()\n",
        "        \n",
        "        query_fp = np.sum(weights[:, None] * rp_features[nearest_idx], axis=0)\n",
        "        query_fp += np.random.randn(len(query_fp)) * noise_std\n",
        "        queries.append(query_fp)\n",
        "    \n",
        "    return np.array(queries), true_locs\n",
        "\n",
        "# Generate test data\n",
        "n_queries = 50\n",
        "noise_std = 2.0  # 2 dBm measurement noise\n",
        "queries, true_locs = generate_test_queries(db, n_queries, floor_id, noise_std)\n",
        "\n",
        "print(f\"Generated {n_queries} test queries with {noise_std} dBm noise\")\n",
        "print(f\"Query fingerprint shape: {queries.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 1: Nearest Neighbor (NN) Positioning\n",
        "print(\"=\"*70)\n",
        "print(\"Example 1: Nearest Neighbor (NN) Positioning - Eq. 5.1\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "nn_errors = []\n",
        "nn_estimates = []\n",
        "\n",
        "for query, true_loc in zip(queries, true_locs):\n",
        "    est_loc = nn_localize(query, db, metric=\"euclidean\", floor_id=floor_id)\n",
        "    nn_estimates.append(est_loc)\n",
        "    nn_errors.append(np.linalg.norm(est_loc - true_loc))\n",
        "\n",
        "nn_errors = np.array(nn_errors)\n",
        "nn_estimates = np.array(nn_estimates)\n",
        "\n",
        "print(f\"\\nüìä NN Results:\")\n",
        "print(f\"  RMSE:            {np.sqrt(np.mean(nn_errors**2)):.2f} m\")\n",
        "print(f\"  Mean error:      {np.mean(nn_errors):.2f} m\")\n",
        "print(f\"  Median error:    {np.median(nn_errors):.2f} m\")\n",
        "print(f\"  90th percentile: {np.percentile(nn_errors, 90):.2f} m\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 2: k-Nearest Neighbor (k-NN) Positioning\n",
        "print(\"=\"*70)\n",
        "print(\"Example 2: k-Nearest Neighbor (k-NN) Positioning - Eq. 5.2\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Test different values of k\n",
        "k_values = [1, 3, 5, 7]\n",
        "knn_results = {}\n",
        "\n",
        "for k in k_values:\n",
        "    knn_errors = []\n",
        "    knn_estimates = []\n",
        "    \n",
        "    for query, true_loc in zip(queries, true_locs):\n",
        "        est_loc = knn_localize(query, db, k=k, metric=\"euclidean\", \n",
        "                               weighting=\"inverse_distance\", floor_id=floor_id)\n",
        "        knn_estimates.append(est_loc)\n",
        "        knn_errors.append(np.linalg.norm(est_loc - true_loc))\n",
        "    \n",
        "    knn_results[k] = {\n",
        "        'errors': np.array(knn_errors),\n",
        "        'estimates': np.array(knn_estimates),\n",
        "        'rmse': np.sqrt(np.mean(np.array(knn_errors)**2)),\n",
        "    }\n",
        "\n",
        "print(f\"\\nüìä k-NN Results (inverse distance weighting):\")\n",
        "print(f\"\\n{'k':<5} {'RMSE (m)':<12} {'Median (m)':<12} {'P90 (m)':<12}\")\n",
        "print(\"-\" * 41)\n",
        "for k, res in knn_results.items():\n",
        "    rmse = res['rmse']\n",
        "    median = np.median(res['errors'])\n",
        "    p90 = np.percentile(res['errors'], 90)\n",
        "    print(f\"{k:<5} {rmse:<12.2f} {median:<12.2f} {p90:<12.2f}\")\n",
        "\n",
        "# Best k\n",
        "best_k = min(knn_results, key=lambda k: knn_results[k]['rmse'])\n",
        "print(f\"\\n‚úÖ Best k = {best_k} (RMSE = {knn_results[best_k]['rmse']:.2f} m)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Part 3: Probabilistic Methods\n",
        "\n",
        "## 3.1 Bayesian Fingerprinting (Eqs. 5.3-5.5)\n",
        "\n",
        "Instead of finding the \"nearest\" fingerprint, compute the **probability** of each location given the observation:\n",
        "\n",
        "### Likelihood (Eq. 5.3)\n",
        "Assuming Gaussian Naive Bayes (each AP independent):\n",
        "\n",
        "$$p(\\mathbf{z} | \\mathbf{x}_i) = \\prod_{j=1}^{M} \\mathcal{N}(z_j; \\mu_{ij}, \\sigma_{ij}^2)$$\n",
        "\n",
        "### MAP Estimate (Eq. 5.4)\n",
        "$$\\hat{\\mathbf{x}}_{MAP} = \\arg\\max_i p(\\mathbf{x}_i | \\mathbf{z}) = \\arg\\max_i p(\\mathbf{z} | \\mathbf{x}_i) p(\\mathbf{x}_i)$$\n",
        "\n",
        "### Posterior Mean (Eq. 5.5)\n",
        "$$\\hat{\\mathbf{x}}_{mean} = \\sum_i p(\\mathbf{x}_i | \\mathbf{z}) \\mathbf{x}_i$$\n",
        "\n",
        "**Advantage**: Provides uncertainty quantification and smoother estimates\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 3: Probabilistic Fingerprinting\n",
        "print(\"=\"*70)\n",
        "print(\"Example 3: Probabilistic Fingerprinting - Eqs. 5.3-5.5\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Fit Gaussian Naive Bayes model\n",
        "print(\"\\nüìà Fitting Gaussian Naive Bayes model...\")\n",
        "model = fit_gaussian_naive_bayes(db, min_std=2.0)\n",
        "print(\"   Model fitted!\")\n",
        "\n",
        "# MAP positioning\n",
        "print(\"\\nüéØ MAP Positioning (Eq. 5.4):\")\n",
        "map_errors = []\n",
        "for query, true_loc in zip(queries, true_locs):\n",
        "    est_loc = map_localize(query, model, floor_id=floor_id)\n",
        "    map_errors.append(np.linalg.norm(est_loc - true_loc))\n",
        "map_errors = np.array(map_errors)\n",
        "\n",
        "print(f\"  RMSE:   {np.sqrt(np.mean(map_errors**2)):.2f} m\")\n",
        "print(f\"  Median: {np.median(map_errors):.2f} m\")\n",
        "\n",
        "# Posterior Mean positioning\n",
        "print(\"\\nüéØ Posterior Mean Positioning (Eq. 5.5):\")\n",
        "pm_errors = []\n",
        "for query, true_loc in zip(queries, true_locs):\n",
        "    est_loc = posterior_mean_localize(query, model, floor_id=floor_id)\n",
        "    pm_errors.append(np.linalg.norm(est_loc - true_loc))\n",
        "pm_errors = np.array(pm_errors)\n",
        "\n",
        "print(f\"  RMSE:   {np.sqrt(np.mean(pm_errors**2)):.2f} m\")\n",
        "print(f\"  Median: {np.median(pm_errors):.2f} m\")\n",
        "\n",
        "print(\"\\nüí° Note: Posterior Mean often provides smoother estimates than MAP\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Part 4: Method Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive comparison visualization\n",
        "print(\"=\"*70)\n",
        "print(\"Method Comparison\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Collect all results\n",
        "all_results = {\n",
        "    'NN': nn_errors,\n",
        "    'k-NN (k=3)': knn_results[3]['errors'],\n",
        "    'k-NN (k=5)': knn_results[5]['errors'],\n",
        "    'MAP': map_errors,\n",
        "    'Posterior Mean': pm_errors,\n",
        "}\n",
        "\n",
        "# Summary table\n",
        "print(f\"\\nüìä Results Summary:\\n\")\n",
        "print(f\"{'Method':<18} {'RMSE (m)':<12} {'Median (m)':<12} {'P90 (m)':<12}\")\n",
        "print(\"-\" * 54)\n",
        "for method, errors in all_results.items():\n",
        "    rmse = np.sqrt(np.mean(errors**2))\n",
        "    median = np.median(errors)\n",
        "    p90 = np.percentile(errors, 90)\n",
        "    print(f\"{method:<18} {rmse:<12.2f} {median:<12.2f} {p90:<12.2f}\")\n",
        "\n",
        "# Visualize\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Plot 1: Box plot comparison\n",
        "ax1 = axes[0]\n",
        "colors = ['#3498db', '#e74c3c', '#2ecc71', '#9b59b6', '#f39c12']\n",
        "bp = ax1.boxplot([all_results[m] for m in all_results], \n",
        "                  labels=list(all_results.keys()), patch_artist=True)\n",
        "for patch, color in zip(bp['boxes'], colors):\n",
        "    patch.set_facecolor(color)\n",
        "    patch.set_alpha(0.7)\n",
        "ax1.set_ylabel('Position Error (m)', fontsize=12)\n",
        "ax1.set_title('Error Distribution by Method', fontsize=14, fontweight='bold')\n",
        "ax1.tick_params(axis='x', rotation=30)\n",
        "ax1.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Plot 2: CDF comparison\n",
        "ax2 = axes[1]\n",
        "for (method, errors), color in zip(all_results.items(), colors):\n",
        "    sorted_errors = np.sort(errors)\n",
        "    cdf = np.arange(1, len(sorted_errors) + 1) / len(sorted_errors)\n",
        "    ax2.plot(sorted_errors, cdf, label=method, color=color, linewidth=2)\n",
        "ax2.axhline(y=0.90, color='gray', linestyle='--', alpha=0.5)\n",
        "ax2.set_xlabel('Position Error (m)', fontsize=12)\n",
        "ax2.set_ylabel('CDF', fontsize=12)\n",
        "ax2.set_title('Cumulative Distribution Function', fontsize=14, fontweight='bold')\n",
        "ax2.legend(fontsize=9)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.set_xlim(0, None)\n",
        "\n",
        "# Plot 3: Spatial visualization (NN vs k-NN)\n",
        "ax3 = axes[2]\n",
        "# Show reference points\n",
        "floor_mask = db.get_floor_mask(floor_id)\n",
        "ax3.scatter(db.locations[floor_mask, 0], db.locations[floor_mask, 1],\n",
        "            c='lightgray', marker='s', s=30, alpha=0.5, label='Reference Points')\n",
        "# Show true vs estimated for first 20 queries\n",
        "for i in range(min(20, len(true_locs))):\n",
        "    ax3.plot([true_locs[i, 0], nn_estimates[i, 0]], \n",
        "             [true_locs[i, 1], nn_estimates[i, 1]], \n",
        "             'r-', alpha=0.3, linewidth=1)\n",
        "ax3.scatter(true_locs[:20, 0], true_locs[:20, 1], c='green', marker='o', \n",
        "            s=50, label='True Location', zorder=5)\n",
        "ax3.scatter(nn_estimates[:20, 0], nn_estimates[:20, 1], c='red', marker='x', \n",
        "            s=50, label='NN Estimate', zorder=5)\n",
        "ax3.set_xlabel('X (m)', fontsize=12)\n",
        "ax3.set_ylabel('Y (m)', fontsize=12)\n",
        "ax3.set_title('NN Positioning Results (sample)', fontsize=14, fontweight='bold')\n",
        "ax3.legend(fontsize=9)\n",
        "ax3.set_aspect('equal')\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Summary\n",
        "\n",
        "## Key Takeaways\n",
        "\n",
        "### 1. Method Categories\n",
        "\n",
        "| Category | Methods | Characteristics |\n",
        "|----------|---------|-----------------|\n",
        "| **Deterministic** | NN, k-NN | Fast, simple, discrete outputs |\n",
        "| **Probabilistic** | MAP, Posterior Mean | Uncertainty quantification, smoother |\n",
        "\n",
        "### 2. Method Selection Guide\n",
        "\n",
        "| Scenario | Recommended | Reason |\n",
        "|----------|-------------|--------|\n",
        "| Real-time, dense RPs | **k-NN (k=3-5)** | Fast, good accuracy |\n",
        "| Sparse RPs | **Posterior Mean** | Better interpolation |\n",
        "| Need uncertainty | **Probabilistic** | Provides confidence |\n",
        "| Maximum speed | **NN** | Single lookup |\n",
        "\n",
        "### 3. Key Findings\n",
        "\n",
        "1. **k-NN often outperforms NN** by averaging multiple neighbors\n",
        "2. **Inverse distance weighting** better than uniform weights\n",
        "3. **Optimal k** depends on RP density (typically k=3-5)\n",
        "4. **Probabilistic methods** provide smoother estimates but are slower\n",
        "\n",
        "## Practical Considerations\n",
        "\n",
        "- **Database quality**: More RPs ‚Üí better accuracy but higher survey cost\n",
        "- **Environment changes**: Furniture, people affect RSS ‚Üí database may need updates\n",
        "- **Multi-floor**: Floor detection is critical before horizontal positioning\n",
        "\n",
        "---\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. **Vary noise level**: How does 1 dBm vs 5 dBm noise affect accuracy?\n",
        "2. **Try sparse database**: Load `ch5_wifi_fingerprint_sparse` - how much accuracy is lost?\n",
        "3. **Weighting schemes**: Compare uniform vs inverse-distance weighting for k-NN\n",
        "\n",
        "---\n",
        "\n",
        "**Next Steps:** Chapter 6 (Dead Reckoning) for sensor-based trajectory estimation!\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
